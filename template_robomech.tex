\documentclass{jarticle}
% \usepackage{flushend}  % 最終ページの2カラムの左右の高さを揃える
\usepackage[dvipdfmx]{graphicx}
\usepackage{subcaption}
\captionsetup[figure]{justification=centering}
\captionsetup[table]{justification=centering}
\usepackage[ipa]{pxchfon}
\usepackage{otf}
\renewcommand{\figurename}{図~}
\renewcommand{\tablename}{表~}
\newcommand{\figref}[1]{\figurename\ref{#1}}
\newcommand{\tabref}[1]{\tablename\ref{#1}}
\usepackage{robomech}
% \usepackage[dvipdfmx,setpagesize=false]{hyperref}



\begin{document}
\makeatletter
\title{視覚と行動のend-to-end学習により\\経路追従行動をオンラインで模倣する手法の提案}
{― データセット収集密度の動的調整による学習の効率化 ―}
{A proposal for an online imitation method of
path-tracking\\ behavior by end-to-end learning of vision and action}
{- Efficiency improvement of learning by dynamic adjustment of dataset collection density -}

\author{
\begin{tabular}{c}
 \hspace*{0.3zw}○学\hspace{1zw}今井悠月 (千葉工大)\hspace{2zw}正\hspace{1zw}上田隆一 (千葉工大)\hspace{2zw}正\hspace{1zw}林原靖男(千葉工大)\\
 \end{tabular}
 \vspace{1zh} \\
 \begin{tabular}{l}
 {\hspace*{4zw}\small Yuzuki IMAI, Chiba Institute of Technology, s20c1015as@s.chibakoudai.jp}\\
 {\hspace*{4zw}\small Ryuichi UEDA, Chiba Institute of Technology}\\
 {\hspace*{4zw}\small Yasuo HAYASHIBARA, Chiba Institute of Technology}\\
\end{tabular}
}
\makeatother

\abstract{ \small 
We have proposed an online imitation method of path-tracking behavior based on end-to-end learning of vision and action.
In recent years, many studies of autonomous movement using end-to-end learning have been reported. However, these studies have also observed deviations from the target path.
One of the possible reasons for this is the lack of training data for returning to the path.
In this paper, we perform end-to-end learning to follow a route generated by a map-based navigation system. The dataset was collected in two ways, one is to learn only the area around the route and the other is to learn the state away from the route, and the generated path-tracking behaviors were analyzed.
In addition, we proposed a new method of collecting teacher data to reinforce the behavior of returning to the path, and verified the effectiveness of the method by experiments using a simulator.
}

\date{} % 日付を出力しない
\keywords{Autonomous mobile robot,  Navigation,  End-to-end learning,  Dataset}

\maketitle
\thispagestyle{empty}
\pagestyle{empty}

\small
\section{緒言}
本研究グループは，移動ロボットにおけるナビゲーション手段の複数化を目標としている．その目標を達成するため，
従来からカメラ画像とロボットの角速度を end-to-end 学習することで，経路追従する手法を提案し，その有効性を
検証してきた\cite{okada}\cite{okada2}\cite{kiyooka}．
本手法は，複数のセンサと地図を入力として生成した行動を，画像を入力とする行動に模倣する．これによりロボット
は，複数のセンサと地図を使用した時と同じ行動を，画像のみで行えるようになる．よって，地図に基づく経路追従と
画像に基づく経路追従の 2 つのナビゲーション手段を獲得できる．これらを状況に応じて高い信頼性が見込まれる方
を選択することで，経路追従を継続できる可能性が高まる．\\
\hspace*{1zw}本研究と同様に，カメラ画像を入力として，end-to-end 学習により経路追従する手法は，いくつか
提案されている．
例えば，Muller らは，人のコントローラ操作と画像を end-to-end 学習することで，オフロード環境で障害物を
回避して走行できることを確認した\cite{off_load}．また，Moridian らは，人のコントローラ操作と画像，測域
センサのデータを end-to-end 学習することで，一定の経路を走行できることを確認した\cite{Moridian}．
さらに，Bojarski らは，画像と人が操作したステアリングの角度を end-to-end 学習することで，自動運転する
手法を提案した\cite{Bojarski}．
これらの手法はすべて人の操作を教師データとしているのに対し，本手法はルールベースの制御器の出力である
角速度を教師データとしている．そのため，データセットの収集に人の操作が不要である．
それに加えて，ロボットが目標経路に復帰する行動を収集できるため，経路追従の継続に有効であることが確認
されている\cite{imai}．\\
\hspace*{1zw}ここで，本手法はロボットを走行させながらデータセットを収集し，それを用いて学習するが，
ロボットの並進速度に関してはこれまで議論されていない．
従来は，常に一定の速度（0.2 m/s）でロボットを走行させていたが，経路の一部で必要以上にデータを収集している
おそれがある．
収集したデータセットの順序は，各ステップ（0.2 s 程度）ごとに無作為に並び替えられ，その中の一部を学習に
用いるため，割合の大きいデータは多く学習され，割合の小さいデータはあまり学習されていない可能性がある．
経路の一部でも学習が不足すると，ロボットは経路追従できないため，データの収集密度を改善し，
学習に用いられるデータの偏りを少なくすることが望まれる．\\
\hspace*{1zw}これを踏まえ，本稿では，まず従来手法における経路追従失敗の一例を取り上げ，
その要因がデータセットの不均衡によるものであるかを明らかにする．
そのうえで，ロボットの並進速度を教師データの値に応じて可変にすることで，データセットの
収集密度を調整し，学習を効率化する手法を提案する．
なお，このような学習を効率化する手法は，これまでに本研究グループでもいくつか提案されている．
例えば，藤原らは，オーバーサンプリングによりデータの不均衡を改善する手法を提案した\cite{fuji}．
また，\CID{8705}橋らは，データを事前に収集し，オフラインで学習する手法を提案した\cite{takahashi}．
さらに，今井らは，モデルの評価に基づき訓練を打ち切る手法を提案した\cite{imai2}．
いずれの手法も訓練時間の短縮に成功しているが，本稿における提案手法とはアプローチが異なる．\\
\hspace*{1zw}本稿では，今井らの手法を採用し，シミュレータで実験する．
ロボットの並進速度を可変にする場合と，そうでない場合で結果を比較することにより，
提案手法の有効性を検証する．


\section{end-to-end学習により経路追従行動を模倣する手法}
本研究グループが従来から提案する手法について述べる．本手法は，\figref{fig:1}に示すように，
64×48にリサイズした画像を入力，ロボットの角速度を出力として， end-to-end で学習する．
なお，一定時間（0.2 s 程度）ごとにデータセットを収集しつつ，学習するが，これを 1 ステップとしている．
1 ステップにつき，画像と角速度をペアにしたデータセットの中から 8 個のデータを抽出し，それ用いて学習する．
ただし，過学習を防ぐために，データセットの順序は 1 ステップごとに入れ替わる．
よって，学習に用いられるデータは，毎回で異なる．
ネットワークは \figref{fig:2} に示すように，
左から順に，入力層 1 ，畳み込み層 3 ，全結合層 2 ，出力層 1 の全 7 層で構成される．
また，本手法は，学習時と学習後でシステムが異なる．以下に，それぞれの構成を述べる．


\begin{figure}[h!]
  \centering
   \includegraphics[height=15.5mm]{./pdf/deplearning1.pdf}
   \caption{The end-to-end learning method}
   \label{fig:1}
\end{figure}

\begin{figure}[h!]
  \centering
   \includegraphics[height=43mm]{pdf/network.pdf}
   \caption{Structure of network}
   \label{fig:2}
\end{figure}


\subsection{地図に基づく経路追従の模倣学習}
地図に基づく経路追従とは，あらかじめ作成した地図と LiDAR，オドメトリなどを用いて，
自己位置推定，経路計画，制御などの複数のタスクを実行し，経路追従する方法である．
ここで，地図に基づく経路追従を模倣学習するシステムを\figref{fig:3}に示す．
学習時には，ルールベースの制御器となる ROS navigation パッケージ\cite{navigation}を用いて，ロボットは
自律移動する．それと同時に，画像と ROS navigation パッケージから出力される
ヨー方向の目標角速度をペアにしたデータセットを収集し，end-to-end で学習する．
ROS navigation パッケージは，並進速度と角速度を出力するが，角速度のみを教師データとし，
並進速度は常に一定（0.2 m/s）とする．
なお，他の研究\cite{Moridian}\cite{Bojarski}に倣い，データセットの収集には 3つのカメラ（左・中央・右）
を用いる．
この時，\tabref{table:1}のように，左右のカメラ画像に対応する目標角速度には，
それぞれ目標経路に戻るようにオフセットを加える．
具体的には，左のカメラには目標角速度に 0.2 rad/s を引いた値を，
右のカメラには目標角速度に 0.2 rad/s を足した値を教師データとする．
これにより，データの量を増やすことや，過学習を防ぐ効果が期待される．
ただし，旋回時（0.1 rad/s 以上）には，中央のカメラのみを使用する．
ロボットのモータを制御するモジュールは，ROS の navigation パッケージから出力される
角速度と，学習器から出力される角速度の 2つで構成されており，この 2つを切り替えることが可能である．

\begin{figure}[h!]
  \centering
   \includegraphics[height=53mm]{./png/learn.png}
   \caption{The end-to-end learning method}
   \label{fig:3}
\end{figure}

% \vspace*{-2zh}

\begin{table}[h!]
  \centering
  \caption{Yaw angular velocity offset per camera}
  \label{table:1}
    \scalebox{0.95}[0.95]{
    \begin{tabular}{|l|l|}
      \hline\hline
      Cameras & Yaw angular velocity offset (rad/s)\\
      \hline\hline
      Left camera & ROS navigation system output $-$ 0.2\\
      \hline
      Center camera & ROS navigation system output\\
      \hline
      Right camera & ROS navigation system output $+$ 0.2\\
      \hline
    \end{tabular} }
\end {table}




\subsection{訓練済みモデルを用いた視覚に基づく経路追従}
学習が終了したら，訓練済みモデルを用いて，経路追従できるかを確認する．
このときのシステム構成を\figref{fig:4}に示す．
ここでは，ROS の navigation パッケージからの出力は使用せずにロボットを制御する．
地図に基づく経路追従の模倣学習時と同様に，画像を学習器に入力し，その推定結果をヨー方向の
目標角速度としてロボットを自律移動させる．
ロボットのヨー方向の角速度には学習器の出力を用いるが，並進速度は常に一定 (0.2 m/s) とする．
また，地図に基づく経路追従の模倣学習時には， 3 つのカメラ（左・中央・右）を用いたが，
訓練済みモデルを用いた視覚に基づく経路追従時には， 3 つのカメラのうち，中央のカメラのみを使用する．

\begin{figure}[h!]
  \centering
   \includegraphics[height=53mm]{./png/afterlearn.png}
   \caption{The end-to-end learning method}
   \label{fig:4}
\end{figure}

\section{モデルの評価に基づき訓練を打ち切る手法}
あああ\\

\begin{figure}[h!]
  \centering
   \includegraphics[height=48mm]{./png/moderu.png}
   \caption{The end-to-end learning method}
  %  \label{fig:2}
\end{figure}

\newpage

\section{従来手法を用いた経路追従失敗の要因調査}
あああ



\begin{figure}[h!]
  \centering
   \includegraphics[height=46mm]{./png/location.png}
   \caption{The end-to-end learning method}
  %  \label{fig:2}
\end{figure}


\begin{figure}[h!]
  \centering
   \includegraphics[height=43mm]{./png/failed.png}
   \caption{The end-to-end learning method}
  %  \label{fig:2}
\end{figure}

\begin{figure}[h!]
  \centering
   \includegraphics[height=43mm]{./png/analy.png}
   \caption{The end-to-end learning method}
  %  \label{fig:2}
\end{figure}


\section{提案手法}
あああ\\

\newpage

\section{シミュレータでの実験}
あああ\\

\section{結言}
本稿では，従来から提案する経路追従行動の模倣手法における経路追従失敗の一例を取り上げ，
その要因がデータセットの不均衡によるものであることを明らかにした．
そのうえで，ロボットの並進速度を教師データの値に応じて可変にすることで，データセットの収集密度を調整
し，学習を効率化する手法を提案した．その後，シミュレータでの実験により提案手法の有効性を検証した．
結果的に，提案手法は従来手法に比べて，データの不均衡を改善し，訓練打ち切りの指標を
早くに満たすことができる傾向が見られたため，有効であることが確認された．

\footnotesize
\begin{thebibliography}{99}

\bibitem{okada}
岡田眞也， 清岡優祐， 上田隆一， 林原靖男，“視覚と行動の end-
to-end 学習により経路追従行動をオンラインで模倣する手法
の提案”，計測自動制御学会 \textit{SI} 部門講演会 \textit{SICE-SI2020} 予稿
集， pp.1148-1152, 2020.

\bibitem{okada2}
岡田眞也, 清岡優祐, 春山健太, 上田隆一, 林原靖男, “視覚と
行動の end-to-end 学習により経路追従行動 をオンラインで
模倣する手法の提案 -経路追従行動の修正のためにデータセッ
トを動的に追加する手法の検討-”, 計測自動制御学会 SI 部門
講演会 SICE-SI2021 予稿集, pp.1066-1080, 2021.

\bibitem{kiyooka}
清岡優祐, 岡田眞也, 岩井一輝, 上田隆一, 林原靖男, “視覚と行動の end-
to-end 学習により経路追従行動 をオンラインで模倣する手法の提案 -データセットと
生成された経路追従行動の解析-”, 計測自動 制御学会 SI 部門講演会 SICE-SI2021 
予稿集, pp.1071-1075, 2021.

\bibitem{off_load}
U. Muller, J. Ben, E. Cosatto, B. Flepp, and Y. Cun.
“Off-Road Obstacle Avoidance through End-to-End Learning.”
Advances in neural information processing systems,
Vol. 18, 2005.

\bibitem{Moridian}
Moridian, Barzin, Anurag Kamal, and Nina Mahmoudian. 
“Learning Navigation Tasks from Demonstration for Semi-autonomous Remote
Operation of Mobile Robots.” 2018 IEEE International Symposium on
Safety, Security, and Rescue Robotics (SSRR), pp.1-8, 2018.

\bibitem{Bojarski}
Bojarski, Mariusz, \textit{et al}.,
“End to end learning for self-driving cars,” arXiv:1604.08316, 2016.

\bibitem{imai}
今井悠月 , 清岡優祐 , 春山健太 , 上田隆一 , 林原靖男 . ” 視覚と行動の end-to-end 学習によ
り経路追従行動をオンラインで模倣する手法の提案
ー経路への復帰行動の解析と復帰
行動を強化する教師データ収集法の検討ー . 日本機械学会ロボティクス・メカトロニクス
講演会 ’23 予稿集 , 2P2-G05(2023).

\bibitem{fuji}
藤原柾，春山健太，馬場琉生，上田隆一，林原靖男，"視覚と行動のend-to-end 学習により経路追従行動を
オンラインで模倣する手法の提案　実環境における経路選択機能の検証と学習時間の短縮化の検討"
，日本機械学会ロボティクス・メカトロニクス講演会'23予稿集，2P2-G06(2023)


\bibitem{takahashi}
\CID{8705}橋祐樹，白須和暉，藤原柾，上田隆一，林原靖男，"視覚と行動のend-to-end 学習による経路追従行動の模倣"，
日本機械学会ロボティクス・メカトロニクス講演会'23予稿集，2P1-G07(2023)

\bibitem{imai2}
今井 悠月、落合 拓海、白須 和暉、上田 隆一、林原 靖男，”視覚と行動のend-to-end 学習により経路追従行動を
オンラインで模倣する手法の提案 モデルの評価に基づく訓練ステップ数の決定”，1B1-04，SI2023，(2023)

\bibitem{navigation}
ros-planning, navigation リポジトリ\\
https://github.com/ros-planning/navigation.\\
( 最終閲覧日 : \today )


\end{thebibliography}

\normalsize
\end{document}
