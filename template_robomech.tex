\documentclass{jarticle}
% \usepackage{flushend}  % 最終ページの2カラムの左右の高さを揃える
\usepackage[dvipdfmx]{graphicx}
\usepackage{subcaption}
\captionsetup[figure]{justification=centering}
\captionsetup[table]{justification=centering}
\usepackage[ipa]{pxchfon}
\usepackage{otf}
\renewcommand{\figurename}{図~}
\renewcommand{\tablename}{表~}
\newcommand{\figref}[1]{\figurename\ref{#1}}
\newcommand{\tabref}[1]{\tablename\ref{#1}}
\usepackage{robomech}
% \usepackage[dvipdfmx,setpagesize=false]{hyperref}



\begin{document}
\makeatletter
\title{視覚と行動のend-to-end学習により\\経路追従行動をオンラインで模倣する手法の提案}
{― データセット収集密度の動的調整による学習の効率化 ―}
{A proposal for an online imitation method of
path-tracking\\ behavior by end-to-end learning of vision and action}
{- Efficiency improvement of learning by dynamic adjustment of dataset collection density -}

\author{
\begin{tabular}{c}
 \hspace*{0.3zw}○学\hspace{1zw}今井悠月 (千葉工大)\hspace{2zw}正\hspace{1zw}上田隆一 (千葉工大)\hspace{2zw}正\hspace{1zw}林原靖男(千葉工大)\\
 \end{tabular}
 \vspace{1zh} \\
 \begin{tabular}{l}
 {\hspace*{4zw}\small Yuzuki IMAI, Chiba Institute of Technology, s20c1015as@s.chibakoudai.jp}\\
 {\hspace*{4zw}\small Ryuichi UEDA, Chiba Institute of Technology}\\
 {\hspace*{4zw}\small Yasuo HAYASHIBARA, Chiba Institute of Technology}\\
\end{tabular}
}
\makeatother

\abstract{ \small 
We have proposed an online imitation method of path-tracking behavior based on end-to-end learning of vision and action.
In recent years, many studies of autonomous movement using end-to-end learning have been reported. However, these studies have also observed deviations from the target path.
One of the possible reasons for this is the lack of training data for returning to the path.
In this paper, we perform end-to-end learning to follow a route generated by a map-based navigation system. The dataset was collected in two ways, one is to learn only the area around the route and the other is to learn the state away from the route, and the generated path-tracking behaviors were analyzed.
In addition, we proposed a new method of collecting teacher data to reinforce the behavior of returning to the path, and verified the effectiveness of the method by experiments using a simulator.
}

\date{} % 日付を出力しない
\keywords{Autonomous mobile robot,  Navigation,  End-to-end learning,  Dataset}

\maketitle
\thispagestyle{empty}
\pagestyle{empty}

\small
\section{緒言}
本研究グループは，移動ロボットにおけるナビゲーション手段の複数化を目標としている．その目標を達成するため，
従来からカメラ画像とロボットの角速度を end-to-end 学習することで，経路追従する手法を提案し，その有効性を
検証してきた\cite{okada}\cite{okada2}\cite{kiyooka}．
本手法は，複数のセンサと地図を入力として生成した行動を，画像を入力とする行動に模倣する．これによりロボット
は，複数のセンサと地図を使用した時と同じ行動を，画像のみで行えるようになる．よって，地図に基づく経路追従と
画像に基づく経路追従の 2 つのナビゲーション手段を獲得できる．これらを状況に応じて高い信頼性が見込まれる方
を選択することで，経路追従を継続できる可能性が高まる．\\
\hspace*{1zw}本研究と同様に，カメラ画像を入力として，end-to-end 学習により経路追従する手法は，いくつか
提案されている．
例えば，Muller らは，人のコントローラ操作と画像を end-to-end 学習することで，オフロード環境で障害物を
回避して走行できることを確認した\cite{off_load}．また，Moridian らは，人のコントローラ操作と画像，測域
センサのデータを end-to-end 学習することで，一定の経路を走行できることを確認した\cite{Moridian}．
さらに，Bojarski らは，画像と人が操作したステアリングの角度を end-to-end 学習することで，自動運転する
手法を提案した\cite{Bojarski}．
これらの手法はすべて人の操作を教師データとしているのに対し，本手法はルールベースの制御器の出力である
角速度を教師データとしている．そのため，データセットの収集に人の操作が不要である．
それに加えて，ロボットが目標経路に復帰する行動を収集できるため，経路追従の継続に有効であることが確認
されている\cite{imai}．\\
\hspace*{1zw}ここで，本手法はロボットを走行させながらデータセットを収集し，それを用いて学習するが，
ロボットの並進速度に関してはこれまで議論されていない．
従来は，常に一定の速度（0.2 m/s）でロボットを走行させていたが，経路の一部で必要以上にデータを収集している
おそれがある．
収集したデータセットの順序は，各ステップ（0.2 s 程度）ごとに無作為に並び替えられ，その中の一部を学習に
用いるため，割合の大きいデータは多く学習され，割合の小さいデータはあまり学習されていない可能性がある．
経路の一部でも学習が不足すると，ロボットは経路追従できないため，データの収集密度を改善し，
学習に用いられるデータの偏りを少なくすることが望まれる．\\
\hspace*{1zw}これを踏まえ，本稿では，まず従来手法における経路追従失敗の一例を取り上げ，
その要因がデータセットの不均衡によるものであるかを明らかにする．
そのうえで，ロボットの並進速度を教師データの値に応じて可変にすることで，データセットの
収集密度を調整し，学習を効率化する手法を提案する．
なお，このような学習を効率化する手法は，これまでに本研究グループでもいくつか提案されている．
例えば，藤原らは，オーバーサンプリングによりデータの不均衡を改善する手法を提案した\cite{fuji}．
また，\CID{8705}橋らは，データを事前に収集し，オフラインで学習する手法を提案した\cite{takahashi}．
さらに，今井らは，モデルの評価に基づき訓練を打ち切る手法を提案した\cite{imai2}．
いずれの手法も訓練時間の短縮に成功しているが，本稿における提案手法とはアプローチが異なる．\\
\hspace*{1zw}本稿では，今井らの手法を採用し，シミュレータで実験する．
ロボットの並進速度を可変にする場合と，そうでない場合で結果を比較することにより，
提案手法の有効性を検証する．


\section{end-to-end学習により経路追従行動を模倣する手法}
本研究グループが従来から提案する手法について述べる．本手法は，\figref{fig:1}に示すように，
64×48にリサイズした画像を入力，ロボットの角速度を出力として， end-to-end で学習する．
なお，一定時間（0.2 s 程度）ごとにデータセットを収集しつつ，学習するが，これを 1 ステップとしている．
1 ステップにつき，画像と角速度をペアにしたデータセットの中から 8 個のデータを抽出し，それ用いて学習する．
ただし，過学習を防ぐために，データセットの順序は 1 ステップごとに入れ替わる．
よって，学習に用いられるデータは，毎回で異なる．
ネットワークは \figref{fig:2} に示すように，
左から順に，入力層 1 ，畳み込み層 3 ，全結合層 2 ，出力層 1 の全 7 層で構成される．
また，本手法は，学習時と学習後でシステムが異なる．以下に，それぞれの構成を述べる．


\begin{figure}[h!]
  \centering
   \includegraphics[height=15.5mm]{./pdf/deplearning1.pdf}
   \caption{The end-to-end learning method}
   \label{fig:1}
\end{figure}

\begin{figure}[h!]
  \centering
   \includegraphics[height=43mm]{pdf/network.pdf}
   \caption{Structure of network}
   \label{fig:2}
\end{figure}


\subsection{地図に基づく経路追従の模倣学習}
地図に基づく経路追従とは，あらかじめ作成した地図と LiDAR，オドメトリなどを用いて，
自己位置推定，経路計画，制御などの複数のタスクを実行し，経路追従する方法である．
ここで，地図に基づく経路追従を模倣学習するシステムを\figref{fig:3}に示す．
学習時には，ルールベースの制御器となる ROS navigation パッケージ\cite{navigation}を用いて，ロボットは
自律移動する．それと同時に，画像と ROS navigation パッケージから出力される
ヨー方向の目標角速度をペアにしたデータセットを収集し，end-to-end で学習する．
ROS navigation パッケージは，並進速度と角速度を出力するが，角速度のみを教師データとし，
並進速度は常に一定（0.2 m/s）とする．
なお，他の研究\cite{Moridian}\cite{Bojarski}に倣い，データセットの収集には 3つのカメラ（左・中央・右）
を用いる．
この時，\tabref{table:1}のように，左右のカメラ画像に対応する目標角速度には，
それぞれ目標経路に戻るようにオフセットを加える．
具体的には，左のカメラには目標角速度に 0.2 rad/s を引いた値を，
右のカメラには目標角速度に 0.2 rad/s を足した値を教師データとする．
これにより，データの量を増やすことや，過学習を防ぐ効果が期待される．
ただし，旋回時（0.1 rad/s 以上）には，中央のカメラのみを使用する．
ロボットのモータを制御するモジュールは，ROS の navigation パッケージから出力される
角速度と，学習器から出力される角速度の 2つで構成されており，この 2つを切り替えることが可能である．
学習器の出力をベースに走行すると，学習ができていない部分でロボットは目標経路から外れることになるため，
目標経路へ復帰する行動をより効率的に収集できる．

\begin{figure}[h!]
  \centering
   \includegraphics[height=53mm]{./png/learn.png}
   \caption{Method to imitate path-tracking behavior}
   \label{fig:3}
\end{figure}

\vspace*{-3.5mm}

\begin{table}[h!]
  \centering
  \caption{Yaw angular velocity offset per camera}
  \label{table:1}
    \scalebox{0.90}[0.90]{
    \begin{tabular}{|l|l|}
      \hline\hline
      Cameras & Yaw angular velocity offset (rad/s)\\
      \hline\hline
      Left camera & ROS navigation system output $-$ 0.2\\
      \hline
      Center camera & ROS navigation system output\\
      \hline
      Right camera & ROS navigation system output $+$ 0.2\\
      \hline
    \end{tabular} }
\end {table}

\subsection{訓練済みモデルを用いた視覚に基づく経路追従}
学習が終了したら，訓練済みモデルを用いて，経路追従できるかを確認する．
このときのシステムを\figref{fig:4}に示す．
ここでは，ROS の navigation パッケージからの出力は使用せずにロボットを制御する．
地図に基づく経路追従の模倣学習時と同様に，画像を学習器に入力し，その推定結果をヨー方向の
目標角速度としてロボットを自律移動させる．
ロボットのヨー方向の角速度には学習器の出力を用いるが，並進速度は常に一定 (0.2 m/s) とする．
また，地図に基づく経路追従の模倣学習時には， 3 つのカメラ（左・中央・右）を用いたが，
訓練済みモデルを用いた視覚に基づく経路追従時には， 3 つのカメラのうち，中央のカメラのみを使用する．

\begin{figure}[h!]
  \centering
   \includegraphics[height=53mm]{./png/afterlearn.png}
   \caption{Vision-based path-tracking using learned model}
   \label{fig:4}
\end{figure}

\section{モデルの評価に基づき訓練を打ち切る手法}
本稿の実験で採用する，今井らが提案した手法について述べる．\figref{fig:5}に本手法のシステムを示す．
2.1節で述べた地図に基づく経路追従の模倣学習手法に，訓練中のモデルを評価し，
望む出力がある程度得られたと判定したら，訓練を終了する仕組みを追加している．
具体的には，ROS navigation パッケージの出力である角速度と，学習器の出力である角速度を比較する．
比較の結果，その差の絶対値が一定値（0.05 rad/s）未満であれば，その地点において望ましい出力が得られている
と判定する．この点を DOL（desired output location）と呼び，判定をステップごとに繰り返す．
データセットを収集しつつ，学習し， DOL の割合が一定値を超えたところで訓練を打ち切る．
これにより，従来は一定のステップ数を用いていた訓練を，訓練の結果に応じて適切なステップ数で打ち切る．
ただし，経路の一部でも DOL が少ないと経路追従できないため，DOL の割合は経路全体に対して
ではなく，経路を分割して算出することが望ましい．
以降，本手法を従来手法と呼ぶこととする．

\begin{figure}[h!]
  \centering
   \includegraphics[height=48mm]{./png/moderu.png}
   \caption{Method to terminate training based on model evaluation}
   \label{fig:5}
\end{figure}

\section{従来手法を用いた経路追従失敗の要因調査}
従来手法では，すべての経由点間で DOL の割合が 33 ％以上 であれば，99％経路追従に成功する
ことが確認されている\cite{imai2}．
ただし，訓練を打ち切る基準を満たしていても経路追従に失敗する例がある．
そこで，再現実験を行い，それによって得た経路追従失敗の一例から要因を調査する．

\subsection{実験装置}
実験はシミュレータで行う．シミュレータには Gazebo\cite{gazebo}，環境には Willow Garage を用いた．
ロボットには TurtleBot3\cite{TurtleBot3}にカメラを 3つ取り付けたモデルを用いた．

\subsection{実験方法}
実験では，はじめに地図に基づく経路追従を模倣学習する．
このとき，ロボットは\figref{fig:6}に示すような緑色の経由点を順次移動する．
学習後は，視覚に基づく経路追従で，経路を 1 周できるか確認する．
壁に衝突することなくコースを 1 周できれば経路追従に成功したと判断する．
なお，並進速度は常に0.2 m/s とする．
ここで，
実験は，経路追従の失敗例を確認するまで行い，失敗例のデータを解析.

\begin{figure}[h!]
  \centering
   \includegraphics[height=45mm]{./png/location.png}
   \caption{Waypoints used in the experiment}
   \label{fig:6}
\end{figure}

\subsection{実験結果}
経路追従失敗の一例を\figref{fig:7}に示す．

\begin{figure}[h!]
  \centering
   \includegraphics[height=40mm]{./png/failed.png}
   \caption{The end-to-end learning method}
   \label{fig:7}
\end{figure}

\newpage

\begin{figure}[h!]
  \centering
   \includegraphics[height=40mm]{./png/set.png}
   \caption{The end-to-end learning method}
  %  \label{fig:2}
\end{figure}

\begin{figure}[h!]
  \centering
   \includegraphics[height=40mm]{./png/gaku.png}
   \caption{The end-to-end learning method}
  %  \label{fig:2}
\end{figure}




\section{提案手法}
提案手法について述べる

\begin{figure}[htbp]
  \begin{minipage}[t]{0.5\linewidth}
    \centering
    \includegraphics[keepaspectratio, scale=0.31]{./png/a.png}
    \subcaption{Path following method}
  \end{minipage}
  \begin{minipage}[t]{0.5\linewidth}
    \centering
    \includegraphics[keepaspectratio, scale=0.31]{./png/b.png}
    \subcaption{Using learning machine output method}
  \end{minipage}\vspace*{2mm}
  \caption{Number of return to path}
\end{figure}

% \newpage

\section{提案手法を用いた実験}
提案手法の有効性を検証するため，実験を行う．

\subsection{実験装置，実験方法}
実験装置や実験方法は 4章と同様であるが，失敗の有無に
かかわらず，100 回実験する．経路追従の成功率と，訓練打ち切りステップ数，データセットの観点から
従来手法と比較し，有効性を評価する．

\subsection{経路追従の成功率}
あああああああああああああああああああああああああああああああああ

\begin{table}[h!]
  \centering
  \caption{Number of successes} \vspace*{2mm}
    \scalebox{0.9}[0.9] {
    \begin{tabular}{|c|c|}
      \hline\hline
      Experiments & Number of successes \\
      \hline\hline
      Conventional method & 99/100 \\
      Proposed method & 99/100\\
      \hline 
    \end{tabular} }
\end {table}

\subsection{訓練打ち切りステップ数}
あああああああああああああああああああああああああああああああああああああ


\begin{figure}[htbp]
  \begin{minipage}[t]{0.5\linewidth}
    \centering
    \includegraphics[keepaspectratio, scale=0.27]{./png/c.png}
    \subcaption{Path following method}
  \end{minipage}
  \begin{minipage}[t]{0.5\linewidth}
    \centering
    \includegraphics[keepaspectratio, scale=0.273]{./png/p.png}
    \subcaption{Using learning machine output method}
  \end{minipage}\vspace*{2mm}
  \caption{Number of return to path}
\end{figure}


\subsection{収集および学習したデータセット}
ああああああああああああああああああああああああ


\begin{figure}[h!]
  \centering
   \includegraphics[height=37mm]{./png/dataset_pro2.png}
   \caption{The end-to-end learning method}
  %  \label{fig:2}
\end{figure}

\begin{figure}[h!]
  \centering
   \includegraphics[height=37mm]{./png/gaku_pro2.png}
   \caption{The end-to-end learning method}
  %  \label{fig:2}
\end{figure}

\newpage

\section{結言}
本稿では，従来から提案する経路追従行動の模倣手法における経路追従失敗の一例を取り上げ，
その要因がデータセットの不均衡によるものであることを明らかにした．
そのうえで，ロボットの並進速度を教師データの値に応じて可変にすることで，データセットの収集密度を調整
し，学習を効率化する手法を提案した．その後，シミュレータでの実験により提案手法の有効性を検証した．
結果的に，提案手法は従来手法に比べて，データの不均衡を改善し，訓練打ち切りの指標を
早くに満たすことができる傾向が見られたため，有効であることが確認された．\\

\footnotesize
\begin{thebibliography}{99}

\bibitem{okada}
岡田眞也， 清岡優祐， 上田隆一， 林原靖男，“視覚と行動の end-
to-end 学習により経路追従行動をオンラインで模倣する手法
の提案”，計測自動制御学会 \textit{SI} 部門講演会 \textit{SICE-SI2020} 予稿
集， pp.1148-1152, 2020.

\bibitem{okada2}
岡田眞也, 清岡優祐, 春山健太, 上田隆一, 林原靖男, “視覚と
行動の end-to-end 学習により経路追従行動 をオンラインで
模倣する手法の提案 -経路追従行動の修正のためにデータセッ
トを動的に追加する手法の検討-”, 計測自動制御学会 SI 部門
講演会 SICE-SI2021 予稿集, pp.1066-1080, 2021.

\bibitem{kiyooka}
清岡優祐, 岡田眞也, 岩井一輝, 上田隆一, 林原靖男, “視覚と行動の end-
to-end 学習により経路追従行動 をオンラインで模倣する手法の提案 -データセットと
生成された経路追従行動の解析-”, 計測自動 制御学会 SI 部門講演会 SICE-SI2021 
予稿集, pp.1071-1075, 2021.

\bibitem{off_load}
U. Muller, J. Ben, E. Cosatto, B. Flepp, and Y. Cun.
“Off-Road Obstacle Avoidance through End-to-End Learning.”
Advances in neural information processing systems,
Vol. 18, 2005.

\bibitem{Moridian}
Moridian, Barzin, Anurag Kamal, and Nina Mahmoudian. 
“Learning Navigation Tasks from Demonstration for Semi-autonomous Remote
Operation of Mobile Robots.” 2018 IEEE International Symposium on
Safety, Security, and Rescue Robotics (SSRR), pp.1-8, 2018.

\bibitem{Bojarski}
Bojarski, Mariusz, \textit{et al}.,
“End to end learning for self-driving cars,” arXiv:1604.08316, 2016.

\bibitem{imai}
今井悠月 , 清岡優祐 , 春山健太 , 上田隆一 , 林原靖男 . ” 視覚と行動の end-to-end 学習によ
り経路追従行動をオンラインで模倣する手法の提案
ー経路への復帰行動の解析と復帰
行動を強化する教師データ収集法の検討ー . 日本機械学会ロボティクス・メカトロニクス
講演会 ’23 予稿集 , 2P2-G05(2023).

\bibitem{fuji}
藤原柾，春山健太，馬場琉生，上田隆一，林原靖男，"視覚と行動のend-to-end 学習により経路追従行動を
オンラインで模倣する手法の提案　実環境における経路選択機能の検証と学習時間の短縮化の検討"
，日本機械学会ロボティクス・メカトロニクス講演会'23予稿集，2P2-G06(2023)


\bibitem{takahashi}
\CID{8705}橋祐樹，白須和暉，藤原柾，上田隆一，林原靖男，"視覚と行動のend-to-end 学習による経路追従行動の模倣"，
日本機械学会ロボティクス・メカトロニクス講演会'23予稿集，2P1-G07(2023)

\bibitem{imai2}
今井 悠月、落合 拓海、白須 和暉、上田 隆一、林原 靖男，”視覚と行動のend-to-end 学習により経路追従行動を
オンラインで模倣する手法の提案 モデルの評価に基づく訓練ステップ数の決定”，1B1-04，SI2023，(2023)

\bibitem{navigation}
ros-planning, navigation リポジトリ\\
https://github.com/ros-planning/navigation.\\
( 最終閲覧日 : \today )

\bibitem{gazebo}
Nathan Koenig and Andrew Howard, “Design and use paradigms for gazebo, an
open-source multi-robot simulator,” \textit{2004 IEEE/RSJ International Conference
on Intelligent Robots and Systems (IROS)}, Vol.3, pp.
2149-2154, 2004.

\bibitem{TurtleBot3}
Erico Guizzo and Ackerman Evan, “The TurtleBot3 Teacher [Resources Hands On],
” \textit{IEEE Spectrum}, Vol.54, pp.19-20, August 2017.
\vspace*{2mm}


\end{thebibliography}

\normalsize
\end{document}
